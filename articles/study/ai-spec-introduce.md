# AI Spec 工作流初体验

## AI 工作流的演进历程

起初 GPT-3 时代，输入的文本（Prompt）是个对话框，还会限制输入字符的长度，用 token 来计费。当对话次数多了后，大概消耗 2k-4k tokens 后模型就表现出遗忘前文的表现。  
虽然有“滑动窗口”这种妥协方案，把初始提示或最近的对话再传一遍，但长流程的连贯性依旧不尽人意。  

随着模型架构（如 Transformer 注意力机制的改进）和硬件能力的提升，上下文窗口已经能支持甚至 1000k 量级，可大概理解为输入 50w+ 的汉字都没问题，极大地减少了截断问题。  

而这又产生了新的问题，要理解的内容变多了，在回答错几次后可能就开始离答案越来越远，即​​“中间丢失”现象。  
像人类思考一样，总结之前的对话形成结论再带着结论进行下一个对话，算是能缓解部分这类纠偏而产生的误差。  

再后来有了“检索增强生成”技术，即让模型从被动接受输入的信息，转为主动判断需要的知识。比如你问模型组件的报错怎么改，模型会先去读组件的文档，再结合问题进行输出。  
其实对应的既是能读写的智能体（Agent）。而读哪些组件文档起初是靠训练，现在则是搭建以 MCP 为协议的服务。  

渐渐的，从最初 输入->模型生成->结束 的模式，模型开始有各种诸如总结、检索、等待回复等等中间过程，也就有了 AI 工作流。  

而推测工作流（Speculative Workflow，简写为 Spec）是一种将获得结果拆成多个步骤的运行方式。即先出计划书，确认完计划无误后，模型再按计划书分批按序执行。

## Spec 工作流的优缺点

### 优点

* 相比 Vibe Coding 写到哪算哪的即兴发挥，工作流有预先规划相对可控。
* 对模糊或复杂的需求，能拆小拆细，一步步地去确认，而不是一口气做完。
* 工作流中生成的计划书可以比较方便的留档和查阅，而不是把一堆还带问题修复过程的对话导出才能留档。

### 缺点

* 不适合小型需求。比如改个弹窗、优化下函数还得计划一下有点不必了，直接交给 ide 的 agent 然后检查下就行。
* 不适合验收结果不确定的需求。比如生成个网站，要列的计划会非常的多，确认时也不知道结果，不如先用别的工具生成完再对某些点按计划改。

## 准备工作

以下操作以 [CodeBuddy IDE](https://copilot.tencent.com/ide/) 为例。  
当然你也可以用 [spec-kit](https://github.com/github/spec-kit) 之类的工具，内核是一致的。

要让模型采用我们的 Spec 工作流，你需要先为其准备规则（rules）。  
我一般采用 重述需求->技术方案->具体实现清单 即 require -> design -> tasks 的三段式。 

以将项目中所有 `xxModel.ts` 文件名称改为 `xx.model.ts` 为例，  
重述需求会继续明确需求，比如已经是 `xx.model.ts` 的文件怎么处理，是否所有对该文件的引用都修改，等等。  
技术方案会列出，比如用 `grep` 命令还是别的，以及先查找再修改再打包验证等步骤清单。
具体实现我基本就不看了。随着 ide 的执行，可能才发现用打包来验证文件引用会太慢和往复，就该中断执行继续对话调整技术方案，再确认执行。

### require.md

告诉模型重述需求具体该怎么做，就得靠我们的 require.md 提示词怎么写了。
